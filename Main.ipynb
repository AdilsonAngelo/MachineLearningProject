{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from matplotlib import cm as cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4597, 58)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "hsphere = pd.DataFrame([np.random.normal(size=100)*10 for i in range(5000)])\n",
    "hsphere['label'] = ((hsphere[6]**2 + hsphere[20]**2 + hsphere[53]**2 + hsphere[23]**2 + hsphere[87]**2) <= 100) | (((hsphere[10] - 8)**2 + (hsphere[44] +3)**2 + (hsphere[53] - 5)**2) <= 25)\n",
    "\n",
    "abalone = pd.read_csv('abalone.csv', header=None)\n",
    "\n",
    "corral = pd.DataFrame()\n",
    "np.random.seed(0)\n",
    "corral['A0'] = pd.Series(np.random.randint(0, 2, 128))\n",
    "np.random.seed(45)\n",
    "corral['A1'] = pd.Series(np.random.randint(0, 2, 128))\n",
    "np.random.seed(22)\n",
    "corral['B0'] = pd.Series(np.random.randint(0, 2, 128))\n",
    "np.random.seed(6)\n",
    "corral['B1'] = pd.Series(np.random.randint(0, 2, 128))\n",
    "np.random.seed(42)\n",
    "corral['I'] = pd.Series(np.random.randint(0, 100, size=128))\n",
    "clsss = pd.Series((corral['A0'] & corral['A1']) | (corral['B0'] & corral['B1']))\n",
    "np.random.seed(0)\n",
    "sample = clsss.sample(frac=.25).apply(lambda x: 1 if x == 0 else 0)\n",
    "corral['C'] = clsss\n",
    "corral['C'].loc[list(sample.index)] = sample\n",
    "corral['label'] = clsss\n",
    "\n",
    "usps = pd.read_csv('usps.csv')\n",
    "\n",
    "arrhythmia = pd.read_csv('arrhythmia.csv', header=None)\n",
    "\n",
    "gas = pd.read_csv('gas.csv')\n",
    "\n",
    "segment = pd.read_csv('segment.csv')\n",
    "\n",
    "spambase = pd.read_csv('spambase.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEFS functions\n",
    "\n",
    "def to_bin(arr):\n",
    "    return int(''.join(arr.astype('int').astype('str')))\n",
    "\n",
    "\n",
    "def get_hash_code(x, funcs):\n",
    "    res = np.array(\n",
    "        [math.floor((f['a'].dot(x) + f['b'])/f['w']) > 0 for f in funcs])\n",
    "    return to_bin(res)\n",
    "\n",
    "\n",
    "def generate_functions(dim, n_buckets=3, w=10, seed=42):\n",
    "    As = np.random.standard_cauchy(1000)\n",
    "    As = As[(As > -50) & (As < 50)]\n",
    "    Bs = np.random.uniform(0, w + .1, 1000)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    functions = []\n",
    "    for i in range(n_buckets):\n",
    "        a = np.array([np.random.choice(As) for col in range(dim)])\n",
    "        b = np.random.choice(Bs)\n",
    "        functions.append({'a': a, 'b': b, 'w': w})\n",
    "\n",
    "    return functions\n",
    "\n",
    "\n",
    "def NEk(X, Y, lsh_index=None, k=4, n_buckets=3):\n",
    "    S = X\n",
    "    C = Y\n",
    "    c_values = set(C.values)\n",
    "\n",
    "    algo = 'kd_tree'\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm=algo, n_jobs=-1)\n",
    "    knn.fit(S, C)\n",
    "    neighbors = knn.kneighbors(S, n_neighbors=k, return_distance=False)\n",
    "\n",
    "    entropy = 0\n",
    "    for i in range(len(neighbors)):\n",
    "        results = C.iloc[neighbors[i]].copy().append(\n",
    "            C.iloc[[i]], ignore_index=False)\n",
    "        freqs = results.value_counts(normalize=True)\n",
    "        for clss in c_values:\n",
    "            try:\n",
    "                freq = freqs.loc[clss]\n",
    "                entropy += freq * np.log(freq)\n",
    "            except:\n",
    "                pass\n",
    "    return (- 1/len(S)) * entropy\n",
    "\n",
    "#     if lsh_index == None:\n",
    "#         funcs = generate_functions(dim=S.shape[1], n_buckets=n_buckets)\n",
    "#         HASH = S.apply(lambda x: get_hash_code(x, funcs), axis=1)\n",
    "#     else:\n",
    "#         HASH = lsh_index.copy()\n",
    "\n",
    "#     HASH.reindex(S.index)\n",
    "    # start = datetime.now()\n",
    "    # for index, row in S.iterrows():\n",
    "    #     if index in visited:\n",
    "    #         continue\n",
    "\n",
    "    #     mask = HASH == HASH.loc[index]\n",
    "\n",
    "    #     if S[mask].shape[0] >= k:\n",
    "    #         rows = S[mask]\n",
    "    #         labels = C[mask]\n",
    "    #     else:\n",
    "    #         rows = S\n",
    "    #         labels = C\n",
    "\n",
    "    #     knn.fit(rows, labels)\n",
    "\n",
    "    #     neighbors = knn.kneighbors(\n",
    "    #         [row], n_neighbors=k, return_distance=False)[0]\n",
    "    #     results = labels.iloc[neighbors].copy().append(\n",
    "    #         labels.loc[[index]], ignore_index=False)\n",
    "    #     visited = np.append(visited, results.index)\n",
    "    #     freqs = results.value_counts(normalize=True)\n",
    "\n",
    "    #     for clss in c_values:\n",
    "    #         try:\n",
    "    #             freq = freqs.loc[clss]\n",
    "    #             temp_sum += freq * np.log(freq)\n",
    "    #         except:\n",
    "    #             pass\n",
    "    # delta = datetime.now() - start\n",
    "    # print(f'lsh duration: {delta}')\n",
    "    # return (- 1/len(rows)) * temp_sum\n",
    "\n",
    "\n",
    "def NEFS(X, Y, k=4, s=2, n_buckets=3, single_indexed=False):\n",
    "    if s > len(X.columns):\n",
    "        raise Exception('\"s\" must be less or equal to number of columns in X')\n",
    "    elif s == len(X.columns):\n",
    "        return X\n",
    "\n",
    "    F = X.copy()\n",
    "    C = Y.copy()\n",
    "    S = pd.DataFrame()\n",
    "\n",
    "    if single_indexed:\n",
    "        funcs = generate_functions(dim=S.shape[1], n_buckets=n_buckets)\n",
    "        HASH = S.apply(lambda row: get_hash_code(row, funcs), axis=1)\n",
    "    else:\n",
    "        HASH = None\n",
    "\n",
    "    while not (len(S.columns) == s):\n",
    "        nes = {}\n",
    "        for col in list(F):\n",
    "            Scopy = S.copy()\n",
    "            Scopy[col] = F[col]\n",
    "\n",
    "            nes[col] = NEk(Scopy, C, k=k, n_buckets=n_buckets, lsh_index=HASH)\n",
    "\n",
    "        min_col = min(nes, key=nes.get)\n",
    "        S[min_col] = F[min_col]\n",
    "        F.drop(columns=[min_col], inplace=True)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELIEFF functions\n",
    "\n",
    "def RELIEFF(X, Y, k=5, iterations=50):\n",
    "    S = X.copy()\n",
    "    C = Y.copy()\n",
    "    W = np.zeros(S.shape[1])\n",
    "    \n",
    "    algo = 'auto'\n",
    "    knn = KNeighborsClassifier(algorithm=algo, n_jobs=-1)\n",
    "    knn.fit(S, C)\n",
    "\n",
    "    for it in range(iterations):\n",
    "        sample = S.sample().iloc[0]\n",
    "\n",
    "        dists, positions = knn.kneighbors([sample], n_neighbors=len(S), return_distance=True)\n",
    "        positions = positions[0]\n",
    "\n",
    "        hits = []\n",
    "        misses = []\n",
    "        for pos in positions:\n",
    "            if C.loc[sample.name] == C.iloc[pos] and len(hits) < k:\n",
    "                hits.append(S.iloc[pos])\n",
    "            if C.loc[sample.name] != C.iloc[pos] and len(misses) < k:\n",
    "                misses.append(S.iloc[pos])\n",
    "            if len(misses) >= k and len(hits) >= k:\n",
    "                break\n",
    "    \n",
    "        hit = np.mean(hits, axis=0)\n",
    "        miss = np.mean(misses, axis=0)\n",
    "        for i in range(len(W)):\n",
    "            W[i] = W[i] - (sample[i] - hit[i])**2 + (sample[i] - miss[i])**2\n",
    "    print(W)\n",
    "    return [(w, W[w]) for w in range(len(W))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI functions\n",
    "\n",
    "def ENTROPY(Y):\n",
    "    C = Y.copy()\n",
    "    freqs = C.value_counts(normalize=True)\n",
    "    entropy = 0\n",
    "    for clss in set(C.values):\n",
    "        freq = freqs.loc[clss]\n",
    "        entropy += freq * np.log(freq)\n",
    "    return -entropy\n",
    "\n",
    "\n",
    "def COND_ENTROPY(Y, F):\n",
    "    F_values = set(F.values)\n",
    "    F_freqs = F.value_counts(normalize=True)\n",
    "    C_values = set(Y.values)\n",
    "    \n",
    "    cond_entropy = 0\n",
    "    \n",
    "    for f in F_values:\n",
    "        F_freq = F_freqs.loc[f]\n",
    "        f_entropy = 0\n",
    "        for clss in C_values:\n",
    "            freqs = Y.loc[F[F == f].index].value_counts(normalize=True)\n",
    "            try:\n",
    "                freq = freqs.loc[clss]\n",
    "                f_entropy += freq * np.log(freq)\n",
    "            except:\n",
    "                pass\n",
    "        cond_entropy += F_freq * f_entropy\n",
    "    \n",
    "    return -cond_entropy\n",
    "\n",
    "\n",
    "def MI(Y, F):\n",
    "    return ENTROPY(Y) - COND_ENTROPY(Y, F)\n",
    "        \n",
    "    \n",
    "def X_MIFS(X, Y, s):\n",
    "    F = X.copy()\n",
    "    mis = [(col, MI(Y, F[col])) for col in list(F.columns)]\n",
    "    mis.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    cols = [col for col, mi in mis]\n",
    "    return F[cols[:s]]\n",
    "\n",
    "\n",
    "def mRMR_MIFS(X, Y, s):\n",
    "    F = X.copy()\n",
    "    S = pd.DataFrame()\n",
    "    mis = [(col, MI(Y, F[col])) for col in list(F.columns)]\n",
    "    mis.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    max_mi = mis[0][0]\n",
    "    S[max_mi] = F[max_mi]\n",
    "    F.drop(columns=[max_mi])\n",
    "    \n",
    "    S_cols_mis = {}\n",
    "    S_cols_mis[max_mi] = {}\n",
    "    while not (len(S.columns) == s):\n",
    "        beta = 1/len(S.columns)\n",
    "        scores = []\n",
    "        for colF in list(F.columns):\n",
    "                \n",
    "            colF_mi = [mi for col, mi in mis if col == colF][0]\n",
    "            colF_mis = []\n",
    "            \n",
    "            for colS in list(S.columns):\n",
    "                if colF in S_cols_mis[colS]:\n",
    "                    colF_mis.append(S_cols_mis[colS][colF])\n",
    "                else:\n",
    "                    temp_mi = MI(F[colF], S[colS])\n",
    "                    colF_mis.append(temp_mi)\n",
    "                    S_cols_mis[colS][colF] = temp_mi\n",
    "                    \n",
    "            scores.append((colF, colF_mi - beta * sum(colF_mis)))\n",
    "        scores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        max_mi = scores[0][0]\n",
    "        S[max_mi] = F[max_mi]\n",
    "        F.drop(columns=[max_mi])\n",
    "        S_cols_mis[max_mi] = {}\n",
    "        print(S_cols_mis)\n",
    "        \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RRPC function\n",
    "def RRPC(X, Y, s):\n",
    "    S = pd.DataFrame()\n",
    "    corrs = [(col, Y.corr(X[col], method='pearson')) for col in list(X.columns)]\n",
    "    corrs.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    max_col = corrs.pop(0)[0]\n",
    "    S[max_col] = X[max_col]\n",
    "    \n",
    "    while not (len(S.columns) == s):\n",
    "        scores = []\n",
    "        for col in list(X.columns):\n",
    "            if col in list(S.columns): continue\n",
    "            corr = Y.corr(X[col], method='pearson') - 1/len(S.columns) * sum([X[col].corr(S[colS], method='pearson') for colS in list(S.columns)])\n",
    "            scores.append((col, corr))\n",
    "        scores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        max_col = scores.pop(0)[0]\n",
    "        S[max_col] = X[max_col]\n",
    "        \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 02:20:31\n",
      "before removing duplicates: 522\n",
      "after removing duplicates: 375\n",
      "t\n",
      "{'t': {'loc': 4.226813192716841, 'v': 2.564375115590206, 'ev': 1.2129660832018994, 'iv': 2.2247082967134357, 'n': 4.952804508147159, 'v.1': 5.494366212290637, 'l': 3.2986878878708303, 'd': 5.210175224610827, 'i': 5.649874965834332, 'e': 5.6882381438475695, 'b': 3.7780786696911712, 't': 5.6919349288105545, 'lOCode': 4.110265182642865, 'lOComment': 1.8290054519363883, 'lOBlank': 2.6127179286491318, 'locCodeAndComment': 0.6750238336250695, 'uniq_Op': 3.0404460274747374, 'uniq_Opnd': 3.776140375088163, 'total_Op': 4.612232981908551, 'total_Opnd': 4.432603343728075, 'branchCount': 2.5632805081946275}, 'locCodeAndComment': {}}\n",
      "{'t': {'loc': 4.226813192716841, 'v': 2.564375115590206, 'ev': 1.2129660832018994, 'iv': 2.2247082967134357, 'n': 4.952804508147159, 'v.1': 5.494366212290637, 'l': 3.2986878878708303, 'd': 5.210175224610827, 'i': 5.649874965834332, 'e': 5.6882381438475695, 'b': 3.7780786696911712, 't': 5.6919349288105545, 'lOCode': 4.110265182642865, 'lOComment': 1.8290054519363883, 'lOBlank': 2.6127179286491318, 'locCodeAndComment': 0.6750238336250695, 'uniq_Op': 3.0404460274747374, 'uniq_Opnd': 3.776140375088163, 'total_Op': 4.612232981908551, 'total_Opnd': 4.432603343728075, 'branchCount': 2.5632805081946275}, 'locCodeAndComment': {'loc': 0.4789225622725084, 'v': 0.3055940510518589, 'ev': 0.2228555318226939, 'iv': 0.25817450252324003, 'n': 0.5477216708224457, 'v.1': 0.6569329823384695, 'l': 0.20190527100736233, 'd': 0.6068715963797855, 'i': 0.6713270486621168, 'e': 0.6713270486621177, 'b': 0.40034841957780376, 't': 0.6750238336251053, 'lOCode': 0.45108848503294396, 'lOComment': 0.22350719672087416, 'lOBlank': 0.24669194859238575, 'locCodeAndComment': 0.7009736005439919, 'uniq_Op': 0.23057374297571975, 'uniq_Opnd': 0.3564276241825639, 'total_Op': 0.4949245790921397, 'total_Opnd': 0.4692257333244165, 'branchCount': 0.30528137158694735}, 'ev': {}}\n",
      "          t  locCodeAndComment    ev\n",
      "0      1.30                  2   1.4\n",
      "1      1.00                  1   1.0\n",
      "2  48380.48                 10  50.0\n",
      "3   8258.00                  5  10.0\n",
      "4   5116.84                  4  12.0\n",
      "end: 02:58:05\n",
      "duration: 0:37:34.636528\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'start: {start.strftime(\"%H:%M:%S\")}')\n",
    "\n",
    "df = pd.read_csv('kc2.csv').dropna()\n",
    "print(f'before removing duplicates: {len(df)}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'after removing duplicates: {len(df)}')\n",
    "\n",
    "\n",
    "# abalone\n",
    "# df.iloc[:, 0] = df.iloc[:, 0].astype('category').cat.codes\n",
    "# Y = pd.qcut(df.iloc[:, -1], q=4, labels=False)\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]\n",
    "  \n",
    "# for col in list(X.columns):\n",
    "#       print(MI(Y, X[col]))\n",
    "# RELIEFF(X, Y)\n",
    "\n",
    "# main_2 = NEFS(X, Y, k=4, s=2, n_buckets=5)\n",
    "main_2 = mRMR_MIFS(X, Y, 3)\n",
    "print(main_2.head())\n",
    "\n",
    "delta = datetime.now() - start\n",
    "print(f'end: {datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "print(f'duration: {delta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    2\n",
       "18    2\n",
       "19    2\n",
       "20    2\n",
       "21    2\n",
       "22    2\n",
       "23    2\n",
       "24    2\n",
       "dtype: int8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pd.qcut(range(25), 3, labels=['1quartil', '2quartil', '3quartil']).codes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1565px",
    "right": "20px",
    "top": "123px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
